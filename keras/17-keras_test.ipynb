{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于多层感知器的softmax多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.72869406 0.28497422 0.88272701 ... 0.20741214 0.65800083 0.77355537]\n",
      " [0.9757939  0.86132527 0.13241319 ... 0.02936748 0.2721887  0.2905099 ]\n",
      " [0.58520786 0.91361492 0.45446354 ... 0.40892413 0.6865742  0.06893386]\n",
      " ...\n",
      " [0.765664   0.48698284 0.00669922 ... 0.32764397 0.97067879 0.96933851]\n",
      " [0.00778741 0.21710091 0.12319165 ... 0.27383114 0.2247927  0.9569954 ]\n",
      " [0.15612459 0.94020289 0.9451422  ... 0.42853689 0.73193992 0.21013284]]\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "print(x_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 6,154\n",
      "Trainable params: 6,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 885us/step - loss: 2.3971 - acc: 0.1050\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 2.3476 - acc: 0.0940\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3412 - acc: 0.0960\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.3207 - acc: 0.1060\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 2.3201 - acc: 0.1010\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.3135 - acc: 0.0920\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.3230 - acc: 0.0980\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.3096 - acc: 0.0890\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.3065 - acc: 0.1210\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.3156 - acc: 0.1030\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.3040 - acc: 0.1150\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.3055 - acc: 0.1090\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.3087 - acc: 0.1050\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.3090 - acc: 0.0960\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.3016 - acc: 0.1150\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.3038 - acc: 0.1050\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.2996 - acc: 0.1250\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.3062 - acc: 0.1080\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.3007 - acc: 0.0960\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3054 - acc: 0.1180\n",
      "100/100 [==============================] - 0s 170us/step\n",
      "[2.3142478466033936, 0.05000000074505806]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP的二分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41459118 0.5061131  0.86600737 ... 0.1374193  0.45972645 0.08573074]\n",
      " [0.18660935 0.82833403 0.23418878 ... 0.24689861 0.41653244 0.21132136]\n",
      " [0.76282008 0.77084451 0.23246642 ... 0.85422266 0.82236792 0.24089658]\n",
      " ...\n",
      " [0.30770094 0.36109429 0.65318561 ... 0.68592061 0.82795076 0.23341072]\n",
      " [0.72989333 0.35345039 0.27461171 ... 0.13698701 0.31842085 0.28371217]\n",
      " [0.10756288 0.5662686  0.93289919 ... 0.83919963 0.37802158 0.16711338]]\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,569\n",
      "Trainable params: 5,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 513us/step - loss: 0.7083 - acc: 0.5100\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.7015 - acc: 0.5040\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.7054 - acc: 0.4930\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.7014 - acc: 0.5000\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.7001 - acc: 0.5030\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6929 - acc: 0.5420\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.6965 - acc: 0.5180\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6917 - acc: 0.5420\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.7013 - acc: 0.4930\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6927 - acc: 0.5290\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6917 - acc: 0.5380\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6940 - acc: 0.5120\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6938 - acc: 0.5090\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6900 - acc: 0.5410\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6961 - acc: 0.5150\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.6919 - acc: 0.5240\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6887 - acc: 0.5350\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 0.6940 - acc: 0.5340\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.6924 - acc: 0.5300\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.6895 - acc: 0.5290\n",
      "100/100 [==============================] - 0s 390us/step\n",
      "[0.6923155188560486, 0.49000000953674316]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "print(x_train)\n",
    "print(to_categorical(y_train,num_classes=2))\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 类似VGG的卷积神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.14137916 0.22137602 0.49720668]\n",
      "   [0.43220385 0.23159986 0.07311988]\n",
      "   [0.28136307 0.20156313 0.34283739]\n",
      "   ...\n",
      "   [0.21832177 0.27832346 0.41375891]\n",
      "   [0.53210132 0.40106541 0.49924207]\n",
      "   [0.91068496 0.40688535 0.22625396]]\n",
      "\n",
      "  [[0.28091691 0.65409873 0.38031333]\n",
      "   [0.37640194 0.79350137 0.70063561]\n",
      "   [0.7846175  0.39800061 0.18934893]\n",
      "   ...\n",
      "   [0.72286711 0.2789821  0.6362089 ]\n",
      "   [0.37804558 0.96041755 0.23437186]\n",
      "   [0.02744409 0.36915248 0.21526589]]\n",
      "\n",
      "  [[0.06257077 0.2902356  0.24986766]\n",
      "   [0.50201532 0.91031594 0.76080309]\n",
      "   [0.49608848 0.00783108 0.89157941]\n",
      "   ...\n",
      "   [0.87937242 0.12053547 0.47472386]\n",
      "   [0.77134652 0.81030085 0.67675707]\n",
      "   [0.90928464 0.80974009 0.43609375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.69946865 0.9369775  0.0747597 ]\n",
      "   [0.34022435 0.8826004  0.25723906]\n",
      "   [0.42101899 0.76828178 0.57723121]\n",
      "   ...\n",
      "   [0.03228272 0.60252847 0.2981775 ]\n",
      "   [0.79737044 0.78682479 0.55116321]\n",
      "   [0.94765137 0.05034635 0.90036953]]\n",
      "\n",
      "  [[0.32436024 0.04728804 0.87570062]\n",
      "   [0.04313022 0.31283691 0.95429068]\n",
      "   [0.27799331 0.11616022 0.38304251]\n",
      "   ...\n",
      "   [0.72137309 0.80320951 0.48928443]\n",
      "   [0.37073379 0.28454828 0.3010073 ]\n",
      "   [0.37641743 0.74678947 0.52605203]]\n",
      "\n",
      "  [[0.96289363 0.1061864  0.55107822]\n",
      "   [0.78417503 0.15881341 0.46212944]\n",
      "   [0.00442671 0.69467412 0.97023148]\n",
      "   ...\n",
      "   [0.72259695 0.05437874 0.22888716]\n",
      "   [0.88703484 0.93293992 0.38850454]\n",
      "   [0.59447035 0.17861004 0.76027642]]]\n",
      "\n",
      "\n",
      " [[[0.80112643 0.04237424 0.46240132]\n",
      "   [0.69224066 0.65124499 0.19257798]\n",
      "   [0.45224018 0.62316139 0.14877145]\n",
      "   ...\n",
      "   [0.59844052 0.95252074 0.37614992]\n",
      "   [0.776186   0.13539118 0.55001077]\n",
      "   [0.47956673 0.51861512 0.93774659]]\n",
      "\n",
      "  [[0.67927287 0.30443938 0.99690791]\n",
      "   [0.27936888 0.18324424 0.6686233 ]\n",
      "   [0.09311318 0.05735483 0.47524351]\n",
      "   ...\n",
      "   [0.07253285 0.80643061 0.75458227]\n",
      "   [0.7019141  0.31183448 0.77863663]\n",
      "   [0.97802768 0.70416925 0.36222855]]\n",
      "\n",
      "  [[0.94465708 0.55646843 0.26519149]\n",
      "   [0.69836121 0.5909746  0.26570888]\n",
      "   [0.52705407 0.15330544 0.89591078]\n",
      "   ...\n",
      "   [0.59403253 0.28857413 0.56765846]\n",
      "   [0.31766032 0.19895954 0.94862256]\n",
      "   [0.62559957 0.89704502 0.31611884]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.57716441 0.40896862 0.36220981]\n",
      "   [0.86456798 0.9440654  0.81909871]\n",
      "   [0.99277258 0.32399554 0.25536779]\n",
      "   ...\n",
      "   [0.97711967 0.20585092 0.36420855]\n",
      "   [0.51306368 0.79424334 0.36038333]\n",
      "   [0.41015259 0.88454533 0.47973516]]\n",
      "\n",
      "  [[0.48060647 0.13840698 0.14567591]\n",
      "   [0.95980058 0.42289634 0.33525975]\n",
      "   [0.13983481 0.93266924 0.65422013]\n",
      "   ...\n",
      "   [0.79075428 0.69846917 0.92560633]\n",
      "   [0.02184747 0.252839   0.5085275 ]\n",
      "   [0.4910062  0.17259829 0.82441975]]\n",
      "\n",
      "  [[0.6178531  0.5417481  0.61893078]\n",
      "   [0.01548694 0.90319156 0.0112532 ]\n",
      "   [0.05871552 0.08175505 0.29365601]\n",
      "   ...\n",
      "   [0.7578527  0.57031563 0.87009842]\n",
      "   [0.98994171 0.51950436 0.71710271]\n",
      "   [0.5976715  0.56494921 0.92970227]]]\n",
      "\n",
      "\n",
      " [[[0.21104699 0.65615462 0.93208917]\n",
      "   [0.66366212 0.06383994 0.20237157]\n",
      "   [0.49318939 0.56585443 0.16001904]\n",
      "   ...\n",
      "   [0.38586015 0.57166957 0.64175149]\n",
      "   [0.66347396 0.13464099 0.82739132]\n",
      "   [0.28809494 0.03952737 0.18085943]]\n",
      "\n",
      "  [[0.10476339 0.73002756 0.02477657]\n",
      "   [0.09616558 0.47744915 0.80047433]\n",
      "   [0.15524978 0.41023649 0.70657594]\n",
      "   ...\n",
      "   [0.4893323  0.43566455 0.83485995]\n",
      "   [0.25977273 0.40695188 0.67755251]\n",
      "   [0.0284706  0.06397838 0.35394414]]\n",
      "\n",
      "  [[0.96448235 0.39205277 0.67288836]\n",
      "   [0.14588559 0.54708553 0.12040537]\n",
      "   [0.90013637 0.78618918 0.77032584]\n",
      "   ...\n",
      "   [0.97896837 0.08864125 0.03518258]\n",
      "   [0.74714843 0.06071839 0.14450337]\n",
      "   [0.70013804 0.10435298 0.16071397]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.12182286 0.00189311 0.99708919]\n",
      "   [0.77666171 0.47958817 0.23107508]\n",
      "   [0.41992701 0.69898786 0.57708711]\n",
      "   ...\n",
      "   [0.98478303 0.42299958 0.14131575]\n",
      "   [0.26318194 0.16098749 0.36514237]\n",
      "   [0.95693567 0.12394043 0.93476979]]\n",
      "\n",
      "  [[0.92669341 0.47951873 0.50874704]\n",
      "   [0.94258755 0.85014439 0.42045377]\n",
      "   [0.50360776 0.6795357  0.15284428]\n",
      "   ...\n",
      "   [0.75908115 0.75818921 0.86274026]\n",
      "   [0.69055002 0.62750408 0.60114245]\n",
      "   [0.75095773 0.8047884  0.57469417]]\n",
      "\n",
      "  [[0.41353456 0.2307314  0.22033484]\n",
      "   [0.4895484  0.98561707 0.82963404]\n",
      "   [0.9722277  0.05110376 0.28473122]\n",
      "   ...\n",
      "   [0.50351754 0.59408485 0.68079446]\n",
      "   [0.66981913 0.37759891 0.85140658]\n",
      "   [0.55866988 0.87149758 0.98498508]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.47447126 0.39543297 0.54619409]\n",
      "   [0.03595609 0.00243932 0.59178692]\n",
      "   [0.6092415  0.99156942 0.18584068]\n",
      "   ...\n",
      "   [0.55281478 0.7105353  0.4076885 ]\n",
      "   [0.2654187  0.28053991 0.78304473]\n",
      "   [0.66691082 0.99178398 0.08601732]]\n",
      "\n",
      "  [[0.13912416 0.23924451 0.09064011]\n",
      "   [0.73971527 0.11904581 0.5002253 ]\n",
      "   [0.24249547 0.33832742 0.84041049]\n",
      "   ...\n",
      "   [0.35745156 0.35415017 0.57256573]\n",
      "   [0.96717628 0.67214187 0.77957617]\n",
      "   [0.15996056 0.08034672 0.23290465]]\n",
      "\n",
      "  [[0.1802798  0.01206487 0.69664039]\n",
      "   [0.33660682 0.78556185 0.55374981]\n",
      "   [0.53926768 0.08867635 0.16711037]\n",
      "   ...\n",
      "   [0.33353631 0.49619962 0.63286993]\n",
      "   [0.99915023 0.94057332 0.99333034]\n",
      "   [0.70043565 0.12516923 0.19734044]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.3367352  0.33959691 0.35542629]\n",
      "   [0.60002253 0.13580198 0.48770681]\n",
      "   [0.77931502 0.9315251  0.63315668]\n",
      "   ...\n",
      "   [0.42323464 0.76596625 0.70929216]\n",
      "   [0.74954524 0.85176807 0.95985671]\n",
      "   [0.03744994 0.58033223 0.5337954 ]]\n",
      "\n",
      "  [[0.2081755  0.89482834 0.44303883]\n",
      "   [0.93535456 0.5509032  0.80425214]\n",
      "   [0.69758052 0.1294395  0.31765138]\n",
      "   ...\n",
      "   [0.85698217 0.01389448 0.77133388]\n",
      "   [0.73444631 0.0298913  0.0349584 ]\n",
      "   [0.55985608 0.28554031 0.99483325]]\n",
      "\n",
      "  [[0.98495769 0.79047047 0.0528151 ]\n",
      "   [0.66276719 0.43668268 0.730567  ]\n",
      "   [0.48652211 0.35988593 0.03726436]\n",
      "   ...\n",
      "   [0.75827761 0.29859324 0.7784832 ]\n",
      "   [0.49961008 0.94304984 0.52288273]\n",
      "   [0.87676078 0.6310242  0.92209144]]]\n",
      "\n",
      "\n",
      " [[[0.80057476 0.6049137  0.56235753]\n",
      "   [0.7425047  0.87373859 0.18580996]\n",
      "   [0.74628196 0.27876526 0.05328952]\n",
      "   ...\n",
      "   [0.62917708 0.54293968 0.5214869 ]\n",
      "   [0.99203585 0.60499911 0.68715581]\n",
      "   [0.68358922 0.40349417 0.01553342]]\n",
      "\n",
      "  [[0.9512924  0.23213591 0.03492944]\n",
      "   [0.00936299 0.23384502 0.10212372]\n",
      "   [0.28556756 0.89777239 0.33136683]\n",
      "   ...\n",
      "   [0.37993589 0.3628245  0.09095667]\n",
      "   [0.9649214  0.6393541  0.08037315]\n",
      "   [0.17137183 0.89093627 0.87625543]]\n",
      "\n",
      "  [[0.43446056 0.55362872 0.67288585]\n",
      "   [0.81395775 0.87197554 0.99730867]\n",
      "   [0.4936205  0.5996484  0.21804196]\n",
      "   ...\n",
      "   [0.35694571 0.73618062 0.72055075]\n",
      "   [0.23163175 0.91347453 0.07686413]\n",
      "   [0.1906298  0.95755761 0.39935988]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.61889582 0.2771522  0.33301583]\n",
      "   [0.85161776 0.73612925 0.51021913]\n",
      "   [0.46225897 0.47164006 0.82009239]\n",
      "   ...\n",
      "   [0.94435166 0.33322612 0.1851465 ]\n",
      "   [0.46932185 0.81829237 0.92524929]\n",
      "   [0.68373424 0.38482671 0.96554698]]\n",
      "\n",
      "  [[0.68539127 0.55000365 0.56471295]\n",
      "   [0.19527902 0.76739301 0.53841337]\n",
      "   [0.44493452 0.24105846 0.59270094]\n",
      "   ...\n",
      "   [0.1790466  0.2709317  0.82636035]\n",
      "   [0.44185967 0.59282983 0.63473614]\n",
      "   [0.7847663  0.40406881 0.04324121]]\n",
      "\n",
      "  [[0.36585033 0.66489053 0.03595532]\n",
      "   [0.27160656 0.52551322 0.23038287]\n",
      "   [0.43658497 0.42208159 0.48627104]\n",
      "   ...\n",
      "   [0.03864796 0.99090093 0.92803376]\n",
      "   [0.73753904 0.77621688 0.11643586]\n",
      "   [0.18030068 0.41071727 0.87536517]]]\n",
      "\n",
      "\n",
      " [[[0.28029616 0.24821124 0.90565286]\n",
      "   [0.01884989 0.37423661 0.2089593 ]\n",
      "   [0.60999355 0.01834717 0.85435326]\n",
      "   ...\n",
      "   [0.37859115 0.97331317 0.11882154]\n",
      "   [0.1954716  0.00376208 0.81581549]\n",
      "   [0.13250934 0.54048218 0.59481042]]\n",
      "\n",
      "  [[0.71083402 0.0093055  0.23347914]\n",
      "   [0.38892443 0.17715532 0.14810273]\n",
      "   [0.84318292 0.75383185 0.1993753 ]\n",
      "   ...\n",
      "   [0.04195088 0.50194373 0.61093456]\n",
      "   [0.29932118 0.03280671 0.90317534]\n",
      "   [0.55399928 0.25756528 0.96364825]]\n",
      "\n",
      "  [[0.77794423 0.9839384  0.52420215]\n",
      "   [0.46750476 0.02776512 0.5168977 ]\n",
      "   [0.39938623 0.4992425  0.56863647]\n",
      "   ...\n",
      "   [0.18893454 0.39326207 0.71327628]\n",
      "   [0.91679264 0.51731252 0.04088225]\n",
      "   [0.318245   0.84193786 0.04881358]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.81798588 0.02270595 0.8210889 ]\n",
      "   [0.8409537  0.12579147 0.47880476]\n",
      "   [0.31969578 0.00948031 0.13185627]\n",
      "   ...\n",
      "   [0.70727049 0.59885819 0.20970067]\n",
      "   [0.72680369 0.2536292  0.59479238]\n",
      "   [0.69114113 0.78508033 0.82012954]]\n",
      "\n",
      "  [[0.51909408 0.33169418 0.01404174]\n",
      "   [0.39962535 0.63108306 0.01207644]\n",
      "   [0.42020773 0.74473647 0.27393007]\n",
      "   ...\n",
      "   [0.17958836 0.71922736 0.00139967]\n",
      "   [0.00184846 0.35377775 0.23069403]\n",
      "   [0.127843   0.10541155 0.43582408]]\n",
      "\n",
      "  [[0.78483308 0.40354942 0.7602136 ]\n",
      "   [0.77455676 0.30341409 0.47104441]\n",
      "   [0.46094407 0.9362144  0.47157862]\n",
      "   ...\n",
      "   [0.37487437 0.14876441 0.5707708 ]\n",
      "   [0.37384107 0.13975742 0.54982376]\n",
      "   [0.79429225 0.68251584 0.91558651]]]] (100, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "print(x_train,x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               7930112   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 7,998,250\n",
      "Trainable params: 7,998,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 5s 52ms/step - loss: 2.3795\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.3594\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 2.2923\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.2823\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.3044\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.2949\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 2.2917\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 2.2986\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 4s 43ms/step - loss: 2.2763\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 2.2944\n",
      "20/20 [==============================] - 0s 16ms/step\n",
      "2.3345773220062256\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用LSTM的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46326398 0.88692632 0.29164171 0.38240873 0.55533191 0.65316529\n",
      "  0.46218083 0.0155836  0.14689879 0.22734137]]\n",
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 256)         256       \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 197,505\n",
      "Trainable params: 197,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_16 to have shape (1,) but got array with shape (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-7adae8dba937>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1635\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1636\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1637\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1638\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1485\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1488\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1489\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_16 to have shape (1,) but got array with shape (10,)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "x_train = np.random.random((1,10))\n",
    "y_tran = np.random.randint(2,size = (1,1))\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "model = Sequential()\n",
    "model.add(Embedding(1, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用1D卷积的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 120, 64)           19264     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 118, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 39, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 37, 128)           24704     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 35, 128)           49280     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 105,729\n",
      "Trainable params: 105,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(122, 100)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "# score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用于序列分类的栈式LSTM\n",
    "在该模型中，我们将三个LSTM堆叠在一起，是该模型能够学习更高层次的时域特征表示。\n",
    "\n",
    "开始的两层LSTM返回其全部输出序列，而第三层LSTM只返回其输出序列的最后一步结果，从而其时域维度降低（即将输入序列转换为单个向量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 8, 32)             6272      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 8, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 23,242\n",
      "Trainable params: 23,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.6097 - acc: 0.1050 - val_loss: 11.7319 - val_acc: 0.0700\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 11.6085 - acc: 0.1010 - val_loss: 11.7319 - val_acc: 0.1000\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 11.6072 - acc: 0.1010 - val_loss: 11.7297 - val_acc: 0.1000\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 203us/step - loss: 11.6072 - acc: 0.0990 - val_loss: 11.7305 - val_acc: 0.0800\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 188us/step - loss: 11.6070 - acc: 0.0940 - val_loss: 11.7311 - val_acc: 0.1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x193903a63c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 采用stateful LSTM的相同模型\n",
    "stateful LSTM的特点是，在处理过一个batch的训练数据后，其内部状态（记忆）会被作为下一个batch的训练数据的初始状态。状态LSTM使得我们可以在合理的计算复杂度内处理较长序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320 samples, validate on 96 samples\n",
      "Epoch 1/5\n",
      "320/320 [==============================] - 2s 6ms/step - loss: 11.4305 - acc: 0.1125 - val_loss: 11.4504 - val_acc: 0.0729\n",
      "Epoch 2/5\n",
      "320/320 [==============================] - 0s 293us/step - loss: 11.4255 - acc: 0.1156 - val_loss: 11.4467 - val_acc: 0.0625\n",
      "Epoch 3/5\n",
      "320/320 [==============================] - ETA: 0s - loss: 11.4452 - acc: 0.12 - 0s 293us/step - loss: 11.4244 - acc: 0.1219 - val_loss: 11.4456 - val_acc: 0.0729\n",
      "Epoch 4/5\n",
      "320/320 [==============================] - 0s 244us/step - loss: 11.4237 - acc: 0.1250 - val_loss: 11.4451 - val_acc: 0.0729\n",
      "Epoch 5/5\n",
      "320/320 [==============================] - 0s 342us/step - loss: 11.4231 - acc: 0.1250 - val_loss: 11.4450 - val_acc: 0.0729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1939cb6a668>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Expected input batch shape: (batch_size, timesteps, data_dim)\n",
    "# Note that we have to provide the full batch_input_shape since the network is stateful.\n",
    "# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((batch_size * 10, timesteps, data_dim))\n",
    "y_train = np.random.random((batch_size * 10, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((batch_size * 3, timesteps, data_dim))\n",
    "y_val = np.random.random((batch_size * 3, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, epochs=5, shuffle=False,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 140, 256)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 140, 256)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  (None, 64)           82176       input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           lstm_12[0][0]                    \n",
      "                                                                 lstm_12[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            129         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 82,305\n",
      "Trainable params: 82,305\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "tweet_a = Input(shape=(140, 256))\n",
    "tweet_b = Input(shape=(140, 256))\n",
    "# This layer can take as input a matrix\n",
    "# and will return a vector of size 64\n",
    "shared_lstm = LSTM(64)\n",
    "\n",
    "# When we reuse the same layer instance\n",
    "# multiple times, the weights of the layer\n",
    "# are also being reused\n",
    "# (it is effectively *the same* layer)\n",
    "encoded_a = shared_lstm(tweet_a)\n",
    "encoded_b = shared_lstm(tweet_b)\n",
    "\n",
    "# We can then concatenate the two vectors:\n",
    "merged_vector = keras.layers.concatenate([encoded_a, encoded_b], axis=-1)\n",
    "\n",
    "# And add a logistic regression on top\n",
    "predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "\n",
    "# We define a trainable model linking the\n",
    "# tweet inputs to the predictions\n",
    "model = Model(inputs=[tweet_a, tweet_b], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inception模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_26/Relu:0\", shape=(?, 256, 256, 64), dtype=float32)\n",
      "Tensor(\"conv2d_28/Relu:0\", shape=(?, 256, 256, 64), dtype=float32)\n",
      "Tensor(\"conv2d_29/Relu:0\", shape=(?, 256, 256, 64), dtype=float32)\n",
      "Tensor(\"concatenate_6/concat:0\", shape=(?, 768, 256, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "print(tower_1)\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "print(tower_2)\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "print(tower_3)\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卷积层的残差连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_35/BiasAdd:0\", shape=(?, 256, 256, 3), dtype=float32)\n",
      "Tensor(\"add_3/add:0\", shape=(?, 256, 256, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Input\n",
    "\n",
    "# input tensor for a 3-channel 256x256 image\n",
    "x = Input(shape=(256, 256, 3))\n",
    "# 3x3 conv with 3 output channels (same as input channels)\n",
    "y = Conv2D(3, (3, 3), padding='same')(x)\n",
    "# this returns x + y.\n",
    "z = keras.layers.add([x, y])\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 共享视觉模型\n",
    "\n",
    "该模型在两个输入上重用了图像处理的模型，用来判别两个MNIST数字是否是相同的数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# First, define the vision modules\n",
    "digit_input = Input(shape=(27, 27, 1))\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "out = Flatten()(x)\n",
    "\n",
    "vision_model = Model(digit_input, out)\n",
    "\n",
    "# Then define the tell-digits-apart model\n",
    "digit_a = Input(shape=(27, 27, 1))\n",
    "digit_b = Input(shape=(27, 27, 1))\n",
    "\n",
    "# The vision model will be shared, weights and all\n",
    "out_a = vision_model(digit_a)\n",
    "out_b = vision_model(digit_b)\n",
    "\n",
    "concatenated = keras.layers.concatenate([out_a, out_b])\n",
    "out = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "classification_model = Model([digit_a, digit_b], out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 视觉问答模型\n",
    "\n",
    "在针对一幅图片使用自然语言进行提问时，该模型能够提供关于该图片的一个单词的答案\n",
    "\n",
    "这个模型将自然语言的问题和图片分别映射为特征向量，将二者合并后训练一个logistic回归层，从一系列可能的回答中挑选一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_53 (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 30, 256)      2560000     input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_52 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                  (None, 256)          525312      embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_37 (Sequential)      (None, 160000)       1735488     input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 160256)       0           lstm_24[0][0]                    \n",
      "                                                                 sequential_37[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1000)         160257000   concatenate_8[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 165,077,800\n",
      "Trainable params: 165,077,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "# First, let's define a vision model using a Sequential model.\n",
    "# This model will encode an image into a vector.\n",
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Flatten())\n",
    "# vision_model.summary()\n",
    "\n",
    "# Now let's get a tensor with the output of our vision model:\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "encoded_image = vision_model(image_input)\n",
    "# print(encoded_image)\n",
    "\n",
    "# Next, let's define a language model to encode the question into a vector.\n",
    "# Each question will be at most 100 word long,\n",
    "# and we will index words as integers from 1 to 9999.\n",
    "question_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=30)(question_input)\n",
    "encoded_question = LSTM(256)(embedded_question)\n",
    "\n",
    "# Let's concatenate the question vector and the image vector:\n",
    "merged = keras.layers.concatenate([encoded_question, encoded_image])\n",
    "\n",
    "# And let's train a logistic regression over 1000 words on top:\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "\n",
    "# This is our final model:\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)\n",
    "vqa_model.summary()\n",
    "# The next stage would be training this model on actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 视频问答模型\n",
    "\n",
    "在做完图片问答模型后，我们可以快速将其转为视频问答的模型。在适当的训练下，你可以为模型提供一个短视频（如100帧）\n",
    "然后向模型提问一个关于该视频的问题，如“what sport is the boy playing？”->“football”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "video_input = Input(shape=(100, 224, 224, 3))\n",
    "# This is our video encoded via the previously trained vision_model (weights are reused)\n",
    "encoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # the output will be a sequence of vectors\n",
    "encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector\n",
    "\n",
    "# This is a model-level representation of the question encoder, reusing the same weights as before:\n",
    "question_encoder = Model(inputs=question_input, outputs=encoded_question)\n",
    "\n",
    "# Let's use it to encode the question:\n",
    "video_question_input = Input(shape=(100,), dtype='int32')\n",
    "encoded_video_question = question_encoder(video_question_input)\n",
    "\n",
    "# And this is our video question answering model:\n",
    "merged = keras.layers.concatenate([encoded_video, encoded_video_question])\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_33 (LSTM)               (None, 32)                12416     \n",
      "=================================================================\n",
      "Total params: 12,416\n",
      "Trainable params: 12,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python35\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  if __name__ == '__main__':\n",
      "d:\\program files\\python35\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(32, input_shape=(10, 64), return_sequences=True)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_34 (LSTM)               (None, 10, 32)            12416     \n",
      "=================================================================\n",
      "Total params: 12,416\n",
      "Trainable params: 12,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python35\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "d:\\program files\\python35\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, input_shape=(10, 64), return_sequences=True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_35 (LSTM)               (None, 10, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 10, 32)            12416     \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 10)                1720      \n",
      "=================================================================\n",
      "Total params: 47,160\n",
      "Trainable params: 47,160\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# as the first layer in a Sequential model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(10, 64)))\n",
    "# now model.output_shape == (None, 32)\n",
    "# note: `None` is the batch dimension.\n",
    "model.summary()\n",
    "# the following is identical:\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_dim=64, input_length=10,return_sequences=True))\n",
    "\n",
    "# for subsequent layers, no need to specify the input size:\n",
    "# model.add(LSTM(16))\n",
    "model.summary()\n",
    "# to stack recurrent layers, you must use return_sequences=True\n",
    "# on any recurrent layer that feeds into another recurrent layer.\n",
    "# note that you only need to specify the input size on the first layer.\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 64)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(1000, 64, input_length=10))\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "\n",
    "input_array = np.random.randint(500, size=(10,10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
