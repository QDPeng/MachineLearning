{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80800 images belonging to 101 classes.\n",
      "Found 20200 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input\n",
    "import food_tool as T\n",
    "import numpy as np\n",
    "\n",
    "# import tools.image_gen_extended as T\n",
    "\n",
    "n_classes = 101\n",
    "#keras 中没有这个方法，需要自己实现如何数据增强\n",
    "#作者这里重写了ImageDataGenerator类，使用自己的数据增强方法，但是作者原文中使用的datagen.flow方法因为内存太小\n",
    "#没办法用，所以只能使用给出的datagen.flow_from_directory方法，这个方法目前还不能random crop，而且作者给出的\n",
    "#方法中有bug，我已经进行了修改。\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = T.ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    "    zoom_range=[.8, 1],\n",
    "    channel_shift_range=30,\n",
    "    seed=2147483647,\n",
    "    fill_mode='reflect')\n",
    "train_datagen.config['random_crop_size'] = (224, 224)\n",
    "train_datagen.set_pipeline([T.random_transform, T.random_crop, T.preprocess_input])\n",
    "train_generator = train_datagen.flow_from_directory('./food-101/train_split', batch_size=64,  target_size=(224, 224))\n",
    "# validation \n",
    "val_datagen = T.ImageDataGenerator(seed=2147483647)\n",
    "val_datagen.config['random_crop_size'] = (224, 224)\n",
    "val_datagen.set_pipeline([T.random_transform, T.random_crop, T.preprocess_input])\n",
    "val_generator = val_datagen.flow_from_directory('./food-101/val_split', batch_size=64, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(101, activation=\"softmax\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 2647s 88s/step - loss: 5.0629 - acc: 0.0547 - val_loss: 4.9467 - val_acc: 0.1031\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 2604s 87s/step - loss: 4.1433 - acc: 0.1375 - val_loss: 5.1003 - val_acc: 0.0953\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 2602s 87s/step - loss: 3.7049 - acc: 0.1870 - val_loss: 4.3581 - val_acc: 0.1406\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 2733s 91s/step - loss: 3.4229 - acc: 0.2281 - val_loss: 4.3137 - val_acc: 0.1484\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 2672s 89s/step - loss: 3.1187 - acc: 0.2594 - val_loss: 3.4580 - val_acc: 0.2203\n",
      "Epoch 6/100\n",
      " 4/30 [===>..........................] - ETA: 33:34 - loss: 2.9993 - acc: 0.2852"
     ]
    }
   ],
   "source": [
    "#training\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "import math\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)),input_shape=(224, 224,3),classes=101)\n",
    "# base_model.summary()\n",
    "x = base_model.output\n",
    "x = AveragePooling2D(pool_size=(7, 7))(x)\n",
    "x = Dropout(.4)(x)\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(n_classes, init='glorot_uniform', W_regularizer=l2(.0005), activation='softmax')(x)\n",
    "\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "opt = SGD(lr=.01, momentum=.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model4.{epoch:02d}.hdf5', save_best_only=True)\n",
    "csv_logger = CSVLogger('./food_mobilenet.log')\n",
    "\n",
    "def schedule(epoch):\n",
    "    if epoch < 15:\n",
    "        return .01\n",
    "    elif epoch < 28:\n",
    "        return .002\n",
    "    else:\n",
    "        return .0004\n",
    "lr_scheduler = LearningRateScheduler(schedule)\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=30,\n",
    "                    epochs=100,  \n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=10,\n",
    "                    verbose=1,\n",
    "                    callbacks = [lr_scheduler, csv_logger, checkpointer])\n",
    "# model.fit_generator(train_generator,\n",
    "#                     validation_data=val_generator,\n",
    "#                     nb_val_samples=64,\n",
    "#                     samples_per_epoch=64,\n",
    "#                     nb_epoch=32,\n",
    "#                     verbose=1,\n",
    "#                     callbacks=[lr_scheduler, csv_logger, checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
