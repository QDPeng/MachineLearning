{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.95735045 -0.10964125  1.35833856  2.30459991  1.80469558 -0.06477176\n",
      " -0.28948875  0.61346719  1.2502532  -0.39251752 -0.01089193  0.01062762\n",
      " -0.48037641 -0.24640901  0.0904717  -0.35102312 -0.2872073   1.00434224\n",
      "  0.46385984 -1.45436252  0.72456804  0.57099146  0.45446039 -0.3033449\n",
      "  1.20884539]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# ---------------------------------------------------|\n",
    "# -------------------1D-data-------------------------|\n",
    "# ---------------------------------------------------|\n",
    "\n",
    "# Create graph session \n",
    "sess = tf.Session()\n",
    "# Generate 1D data\n",
    "data_size = 25\n",
    "data_1d = np.random.normal(size=data_size)\n",
    "print(data_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_4:0\", shape=(1, 1, 21, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Placeholder\n",
    "x_input_1d = tf.placeholder(shape=[data_size],dtype=tf.float32)\n",
    "# Create filter for convolution.\n",
    "conv_filter_1 = tf.Variable(tf.random_normal(shape=[1,5,1,1]))\n",
    "\n",
    "# --------Convolution--------\n",
    "def conv_layers_1d(input_1d,my_filter):\n",
    "    input_2d = tf.expand_dims(input_1d,0)\n",
    "    input_3d = tf.expand_dims(input_2d,0)\n",
    "    input_4d = tf.expand_dims(input_3d,3)\n",
    "    #input_4d like (1,1,input_1d,1)\n",
    "    convolution_output = tf.nn.conv2d(input_4d,filter=my_filter,strides=[1,1,1,1],padding='VALID')\n",
    "    #print(convolution_output) #Tensor(\"Conv2D_4:0\", shape=(1, 1, 21, 1), dtype=float32)\n",
    "    conv_output_1d = tf.squeeze(convolution_output)\n",
    "    return conv_output_1d\n",
    "# Create convolution layer\n",
    "conv_output_1 = conv_layers_1d(x_input_1d,conv_filter_1)\n",
    "# --------Activation Function--------\n",
    "def activation(input_1d):\n",
    "    return tf.nn.relu(input_1d)\n",
    "\n",
    "# Create activation layer\n",
    "activation_output_1 = activation(conv_output_1)\n",
    "# --------Max Pool--------\n",
    "def max_pool(input_1d,width):\n",
    "    # Just like 'conv2d()' above, max_pool() works with 4D arrays.\n",
    "    # [batch_size=1, width=1, height=num_input, channels=1]\n",
    "    input_2d = tf.expand_dims(input_1d,0)\n",
    "    input_3d = tf.expand_dims(input_2d,0)\n",
    "    input_4d = tf.expand_dims(input_3d,3)\n",
    "    pool_output = tf.nn.max_pool(input_4d,ksize=[1,1,width,1],strides=[1,1,1,1],padding='VALID')\n",
    "    # Get rid of extra dimensions\n",
    "    pool_output_1d = tf.squeeze(pool_output)\n",
    "    return pool_output_1d\n",
    "\n",
    "maxpool_output_1 = max_pool(activation_output_1,width=5)\n",
    "# help(tf.nn.max_pool)\n",
    "# --------Fully Connected--------\n",
    "def fully_connected(input_layer,num_outputs):\n",
    "    # First we find the needed shape of the multiplication weight matrix:\n",
    "    # The dimension will be (length of input) by (num_outputs)\n",
    "    # tf.pack modified to tf.stack\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer),[num_outputs]]))\n",
    "    # Initialize such weight\n",
    "    weight = tf.random_normal(weight_shape,stddev=0.1)\n",
    "    # Initialize the bias\n",
    "    bias = tf.random_normal(shape=[num_outputs])\n",
    "    # Make the 1D input array into a 2D array for matrix multiplication\n",
    "    input_layer_2d = tf.expand_dims(input_layer,0)\n",
    "    # Perform the matrix multiplication and add the bias\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d,weight),bias)\n",
    "    # Get rid of extra dimensions\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return full_output_1d\n",
    "\n",
    "full_output_1 = fully_connected(maxpool_output_1,num_outputs=5)\n",
    "# Run graph\n",
    "# Initialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "feed_dict = {x_input_1d: data_1d}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_7:0\", shape=(25,), dtype=float32)\n",
      "<tf.Variable 'Variable_6:0' shape=(1, 5, 1, 1) dtype=float32_ref> [[[[-0.95762062]]\n",
      "\n",
      "  [[-1.60981584]]\n",
      "\n",
      "  [[ 0.28044611]]\n",
      "\n",
      "  [[ 0.53298986]]\n",
      "\n",
      "  [[ 0.68885231]]]]\n",
      "Tensor(\"Squeeze_10:0\", shape=(21,), dtype=float32)\n",
      "Convolution Output---> [ 3.94571877 -0.51809794 -4.7385726  -4.86203146 -0.51691747  1.09608054\n",
      " -0.57643098 -2.70871067 -0.893686   -0.02937788 -0.21040976  0.50045335\n",
      "  0.49712873  0.53064537  1.25273395  0.3255533  -1.48772287 -1.33686185\n",
      "  2.71764517  0.41970158 -0.81456453]\n",
      "Tensor(\"Conv2D_12:0\", shape=(10, 3, 3, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Convolution Output\n",
    "print(x_input_1d)\n",
    "print(conv_filter_1,sess.run(conv_filter_1))\n",
    "print(conv_output_1)\n",
    "print(\"Convolution Output--->\",sess.run(conv_output_1,feed_dict=feed_dict))\n",
    "\n",
    "# test conv2d function\n",
    "input = tf.Variable(tf.random_normal([10,5,5,5])) # shape = [batch, in_height, in_width, in_channels]\n",
    "filter = tf.Variable(tf.random_normal([3,3,5,7])) # shape = [filter_height, filter_width, in_channels, out_channels]\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID') #output shape = [batch, height, width, out_channels]\n",
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.94571877  0.          0.          0.          0.          1.09608054\n",
      "  0.          0.          0.          0.          0.          0.50045335\n",
      "  0.49712873  0.53064537  1.25273395  0.3255533   0.          0.\n",
      "  2.71764517  0.41970158  0.        ]\n",
      "[ 3.94571877  1.09608054  1.09608054  1.09608054  1.09608054  1.09608054\n",
      "  0.          0.50045335  0.50045335  0.53064537  1.25273395  1.25273395\n",
      "  1.25273395  1.25273395  2.71764517  2.71764517  2.71764517]\n",
      "[ 0.08316433  0.90245897 -0.26357979 -0.8294543  -0.62079698]\n"
     ]
    }
   ],
   "source": [
    "# Activation Output\n",
    "print(sess.run(activation_output_1, feed_dict=feed_dict))\n",
    "\n",
    "# Max Pool Output\n",
    "print(sess.run(maxpool_output_1, feed_dict=feed_dict))\n",
    "\n",
    "# Fully Connected Output\n",
    "print(sess.run(full_output_1, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------|\n",
    "# -------------------2D-data-------------------------|\n",
    "# ---------------------------------------------------|\n",
    "\n",
    "# Reset Graph\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "# Generate 2D data\n",
    "data_size = [10, 10]\n",
    "data_2d = np.random.normal(size=data_size)\n",
    "\n",
    "# --------Placeholder--------\n",
    "x_input_2d = tf.placeholder(dtype=tf.float32, shape=data_size)\n",
    "\n",
    "\n",
    "# Convolution\n",
    "def conv_layer_2d(input_2d, my_filter):\n",
    "    # Tensorflow's 'conv2d()' function only works with 4D arrays:\n",
    "    # [batch#, width, height, channels], we have 1 batch, and\n",
    "    # 1 channel, but we do have width AND height this time.\n",
    "    # So next we create the 4D array by inserting dimension 1's.\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # Note the stride difference below!\n",
    "    convolution_output = tf.nn.conv2d(input_4d, filter=my_filter, strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    # Get rid of unnecessary dimensions\n",
    "    conv_output_2d = tf.squeeze(convolution_output)\n",
    "    return conv_output_2d\n",
    "\n",
    "\n",
    "# Create Convolutional Filter\n",
    "my_filter = tf.Variable(tf.random_normal(shape=[2, 2, 1, 1]))\n",
    "# Create Convolutional Layer\n",
    "my_convolution_output = conv_layer_2d(x_input_2d, my_filter)\n",
    "\n",
    "\n",
    "# --------Activation--------\n",
    "def activation(input_1d):\n",
    "    return tf.nn.relu(input_1d)\n",
    "\n",
    "\n",
    "# Create Activation Layer\n",
    "my_activation_output = activation(my_convolution_output)\n",
    "\n",
    "\n",
    "# --------Max Pool--------\n",
    "def max_pool(input_2d, width, height):\n",
    "    # Just like 'conv2d()' above, max_pool() works with 4D arrays.\n",
    "    # [batch_size=1, width=given, height=given, channels=1]\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # Perform the max pooling with strides = [1,1,1,1]\n",
    "    # If we wanted to increase the stride on our data dimension, say by\n",
    "    # a factor of '2', we put strides = [1, 2, 2, 1]\n",
    "    pool_output = tf.nn.max_pool(input_4d, ksize=[1, height, width, 1],\n",
    "                                 strides=[1, 1, 1, 1],\n",
    "                                 padding='VALID')\n",
    "    # Get rid of unnecessary dimensions\n",
    "    pool_output_2d = tf.squeeze(pool_output)\n",
    "    return pool_output_2d\n",
    "\n",
    "\n",
    "# Create Max-Pool Layer\n",
    "my_maxpool_output = max_pool(my_activation_output, width=2, height=2)\n",
    "\n",
    "\n",
    "# --------Fully Connected--------\n",
    "def fully_connected(input_layer, num_outputs):\n",
    "    # In order to connect our whole W byH 2d array, we first flatten it out to\n",
    "    # a W times H 1D array.\n",
    "    flat_input = tf.reshape(input_layer, [-1])\n",
    "    # We then find out how long it is, and create an array for the shape of\n",
    "    # the multiplication weight = (WxH) by (num_outputs)\n",
    "    # tf.pack modified to tf.stack\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(flat_input), [num_outputs]]))\n",
    "    # Initialize the weight\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    # Initialize the bias\n",
    "    bias = tf.random_normal(shape=[num_outputs])\n",
    "    # Now make the flat 1D array into a 2D array for multiplication\n",
    "    input_2d = tf.expand_dims(flat_input, 0)\n",
    "    # Multiply and add the bias\n",
    "    full_output = tf.add(tf.matmul(input_2d, weight), bias)\n",
    "    # Get rid of extra dimension\n",
    "    full_output_2d = tf.squeeze(full_output)\n",
    "    return full_output_2d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[[-0.17095304  0.22788841  0.5058319   0.50707757  0.42798865]\n",
      " [ 0.03318463 -0.13764277 -0.20564047  0.01782988  0.69035554]\n",
      " [-0.15543161 -0.02368833 -0.27016124  0.86132699  0.90642607]\n",
      " [ 0.10998848  0.58655697 -0.06125756 -0.64230275 -0.38151535]\n",
      " [-1.21721959  0.90973336  1.09701717 -0.04690319 -0.36419433]]\n",
      "[[ 0.          0.22788841  0.5058319   0.50707757  0.42798865]\n",
      " [ 0.03318463  0.          0.          0.01782988  0.69035554]\n",
      " [ 0.          0.          0.          0.86132699  0.90642607]\n",
      " [ 0.10998848  0.58655697  0.          0.          0.        ]\n",
      " [ 0.          0.90973336  1.09701717  0.          0.        ]]\n",
      "[[ 0.22788841  0.5058319   0.50707757  0.69035554]\n",
      " [ 0.03318463  0.          0.86132699  0.90642607]\n",
      " [ 0.58655697  0.58655697  0.86132699  0.90642607]\n",
      " [ 0.90973336  1.09701717  1.09701717  0.        ]]\n",
      "[ -2.73105294e-01   1.90842509e-01  -3.70442867e-04  -4.80848402e-01\n",
      "   1.76736876e-01]\n"
     ]
    }
   ],
   "source": [
    "# Create Fully Connected Layer\n",
    "my_full_output = fully_connected(my_maxpool_output, 5)\n",
    "\n",
    "# Run graph\n",
    "# Initialize Variables\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "feed_dict = {x_input_2d: data_2d}\n",
    "\n",
    "# Convolution Output\n",
    "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
    "\n",
    "# Activation Output\n",
    "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
    "\n",
    "# Max Pool Output\n",
    "print(sess.run(my_maxpool_output, feed_dict=feed_dict))\n",
    "\n",
    "# Fully Connected Output\n",
    "print(sess.run(my_full_output, feed_dict=feed_dict))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
