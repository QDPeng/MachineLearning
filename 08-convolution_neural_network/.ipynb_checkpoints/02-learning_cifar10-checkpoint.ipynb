{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will build an convolutional neural network to predict the CIFAR-10 data.\n",
    "The script provided will download and unzip the CIFAR-10 data.  Then it will start training a CNN from scratch.  You should see similar output at the end to the following two graphs.\n",
    "\n",
    "![Loss and Accuracy](https://github.com/nfmcclure/tensorflow_cookbook/blob/master/08_Convolutional_Neural_Networks/images/03_cnn2_loss_acc.png?raw=true)\n",
    "\n",
    "Here we see the training loss (left) and the test batch accuracy (right).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import urllib\n",
    "ops.reset_default_graph()\n",
    "\n",
    "#change dir\n",
    "abspath = os.path.abspath(__name__)\n",
    "dirname = os.path.dirname(abspath)\n",
    "os.chdir(dirname)\n",
    "# Start a graph session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Set model parameters\n",
    "batch_size = 128\n",
    "data_dir = 'cifar10'\n",
    "output_every = 50\n",
    "generations = 20000\n",
    "eval_every = 500\n",
    "image_height = 32\n",
    "image_width = 32\n",
    "crop_height = 24\n",
    "crop_width = 24\n",
    "num_channels = 3\n",
    "num_targets = 10\n",
    "extract_folder = 'cifar-10-batches-bin'\n",
    "\n",
    "cifar10_url = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "\n",
    "# Exponential Learning Rate Decay Params\n",
    "learning_rate = 0.1\n",
    "lr_decay = 0.1\n",
    "num_gens_to_wait = 250.\n",
    "\n",
    "# Extract model parameters\n",
    "image_vec_length = image_height * image_width * num_channels\n",
    "record_length = 1 + image_vec_length  # ( + 1 for the 0-9 label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "# Check if file exists, otherwise download it\n",
    "data_file = os.path.join(data_dir,'cifar-10-binary.tar.gz')\n",
    "if os.path.isfile(data_file):\n",
    "    pass\n",
    "else:\n",
    "    # Download file\n",
    "    def progress(block_num,block_size,total_size):\n",
    "        progress_info = [cifar10_url,float(block_num * block_size) / float(total_size) * 100.0]\n",
    "        print('\\r Downloading {} - {:.2f}%'.format(*progress_info), end=\"\")\n",
    "    filepath,_ = urllib.request.urlretrieve(cifar10_url,data_file,progress)\n",
    "    # Extract file\n",
    "    tarfile.open(filepath,'r:gz').extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting/Transforming Data.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 0 for 'Slice_3' (op: 'Slice') with input shapes: [?], [1], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 0 for 'Slice_3' (op: 'Slice') with input shapes: [?], [1], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d517ba5e4b8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Getting/Transforming Data.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;31m# Initialize the data pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_pipline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_logical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;31m# Get batch test images and targets from pipline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_pipline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_logical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d517ba5e4b8d>\u001b[0m in \u001b[0;36minput_pipline\u001b[1;34m(batch_size, train_logical)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mextract_folder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test_batch.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mfilename_queue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_input_producer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_cifar_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m      \u001b[1;31m# min_after_dequeue defines how big a buffer we will randomly sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m#   from -- bigger means better shuffling but slower start up and more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d517ba5e4b8d>\u001b[0m in \u001b[0;36mread_cifar_files\u001b[1;34m(filename_queue, distort_image)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mimage_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_bytes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Extract image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mimage_extracted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_bytes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_vec_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_height\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Reshape image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mimage_uint8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_extracted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#e.g [2,1,0]，就把输入张量的第三维度和第一维度交换。\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[1;34m(input_, begin, size, name)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m   \"\"\"\n\u001b[1;32m--> 547\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(input, begin, size, name)\u001b[0m\n\u001b[0;32m   2894\u001b[0m   \"\"\"\n\u001b[0;32m   2895\u001b[0m   result = _op_def_lib.apply_op(\"Slice\", input=input, begin=begin, size=size,\n\u001b[1;32m-> 2896\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m   2897\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1874\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be rank 1 but is rank 0 for 'Slice_3' (op: 'Slice') with input shapes: [?], [1], []."
     ]
    }
   ],
   "source": [
    "# Define CIFAR reader\n",
    "'''\n",
    "tf.FixedLengthRecordReader是读取固定长度字节数信息(针对bin文件使用FixedLengthRecordReader读取比较合适)，\n",
    "结果表明下次调用时会接着上次读取的位置继续读取文件，而不会从头开始读取。\n",
    "'''\n",
    "def read_cifar_files(filename_queue,distort_image=True):\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_length)\n",
    "    key,record_string = reader.read(filename_queue)\n",
    "    record_bytes = tf.decode_raw(record_string,tf.uint8)\n",
    "    image_label = tf.cast(tf.slice(record_bytes,[0],[1]),tf.int32)\n",
    "    # Extract image\n",
    "    image_extracted = tf.reshape(tf.slice(record_bytes,[1],image_vec_length),[num_channels,image_width,image_height])\n",
    "    # Reshape image\n",
    "    image_uint8 = tf.transpose(image_extracted,[1,2,0]) #e.g [2,1,0]，就把输入张量的第三维度和第一维度交换。\n",
    "    reshaped_image = tf.cast(image_uint8image, tf.float32)\n",
    "    # Randomly Crop image\n",
    "    final_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,crop_width,crop_height)\n",
    "    if distort_image:\n",
    "        # Randomly flip the image horizontally, change the brightness and contrast\n",
    "        final_image = tf.image.flip_left_right(final_image)\n",
    "        final_image = tf.image.random_brightness(final_image, max_delta=63)\n",
    "        final_image = tf.image.random_contrast(final_image, lower=0.2, upper=1.8)\n",
    "    # Normalize whitening\n",
    "    final_image = tf.image.per_image_standardization(final_image) #f.image.per_image_whitening() 更名为 tf.image.per_image_standardization()\n",
    "    return (final_image,image_label)\n",
    "\n",
    "# Create a CIFAR image pipeline from reader\n",
    "def input_pipline(batch_size,train_logical=True):\n",
    "    if train_logical:\n",
    "        files = [os.path.join(data_dir,extract_folder,'data_batch_{}.bin'.format(i)) for i in range(1,6)]\n",
    "    else:\n",
    "        files = [os.path.join(data_dir,extract_folder,'test_batch.bin')]\n",
    "    filename_queue = tf.train.string_input_producer(files)\n",
    "    image,label = read_cifar_files(filename_queue)\n",
    "     # min_after_dequeue defines how big a buffer we will randomly sample\n",
    "    #   from -- bigger means better shuffling but slower start up and more\n",
    "    #   memory used.\n",
    "    # capacity must be larger than min_after_dequeue and the amount larger\n",
    "    #   determines the maximum we will prefetch.  Recommendation:\n",
    "    #   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "    min_after_dequeue = 5000\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    example_batch,label_batch = tf.train.shuffle_batch([image,label],\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      capacity=capacity,\n",
    "                                                      min_after_dequeue=min_after_dequeue)\n",
    "    return (example_batch, label_batch)\n",
    "\n",
    "# Define the model architecture, this will return logits from images\n",
    "def cifar_cnn_model(input_images,batch_size,train_logical=True):\n",
    "    def truncated_normal_var(name,shape,dtype):\n",
    "        return (tf.get_variable(name=name,shape=shape,dtype=dtype,initializer=tf.truncated_normal_initializer(0.05)))\n",
    "    def zero_var(name,shape,dtype):\n",
    "        return(tf.get_variable(name=name,shape=shape,dtype=dtype,initializer=tf.constant_initializer(0.0)))\n",
    "    \n",
    "    # First Convolutional Layer\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        #Conv_kernel is 5x5 for all 3 colors and we will create 64 features\n",
    "        conv1_kernel = truncated_normal_var(name='conv_kernel1',shape=[5,5,3,64],dtype=tf.float32)\n",
    "        # We convolve across the image with a stride size of 1\n",
    "        conv1 = tf.nn.conv2d(input=input_images,filter=conv1_kernel,strides=[1,1,1,1],padding=\"SAME\")\n",
    "        # Initialize and add the bias term\n",
    "        conv1_bias = zero_var(name=\"conv_bias1\",shape=[64],dtype=tf.float32)\n",
    "        conv1_add_bias = tf.nn.bias_add(conv1,conv1_bias)\n",
    "        #relu element wise\n",
    "        relu_conv1 = tf.nn.relu(conv1_add_bias)\n",
    "            \n",
    "    # Max Pooling\n",
    "    pool1 = tf.nn.max_pool(relu_conv1,ksize=[1,3,3,1],strides=[1,2,2,1],padding=\"SAME\",name=\"pool_layer1\")\n",
    "    # Local Response Normalization (parameters from paper)\n",
    "    # paper: http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks\n",
    "    norm1 = tf.nn.lrn(pool1,depth_radius=5,bias=2.0,alpha=1e-3,beta=0.75,name=\"norm1\")\n",
    "    \n",
    "    # Second Convolutional Layer\n",
    "    with tf.variable_scope(\"conv2\") as scope:\n",
    "        # Conv kernel is 5x5, across all prior 64 features and we create 64 more features\n",
    "        conv2_kernel = truncated_normal_var(name=\"conv_kernel2\",shape=[5,5,64,64],dtype=tf.float32)\n",
    "        # Convolve filter across prior output with stride size of 1\n",
    "        conv2 = tf.nn.conv2d(norm1,conv2_kernel,strides=[1,1,1,1],padding=\"SAME\")\n",
    "        # Initialize and add the bias\n",
    "        conv2_bias = zero_var(name='conv_bias2', shape=[64], dtype=tf.float32)\n",
    "        conv2_add_bias = tf.nn.bias_add(conv2, conv2_bias)\n",
    "        # ReLU element wise\n",
    "        relu_conv2 = tf.nn.relu(conv2_add_bias)\n",
    "    #max pooling\n",
    "    pool2 = tf.nn.max_pool(relu_conv2,ksize=[1,3,3,1],strides=[1,2,2,1],padding=\"SAME\",name=\"pool_layer2\")\n",
    "    # Local Response Normalization (parameters from paper)\n",
    "    norm2 = tf.nn.lrn(pool2, depth_radius=5, bias=2.0, alpha=1e-3, beta=0.75, name='norm2')\n",
    "    # Reshape output into a single matrix for multiplication for the fully connected layers\n",
    "    reshaped_output = tf.reshape(norm2,[batch_size,-1])\n",
    "    reshaped_dim = reshaped_output.get_shape()[1].value\n",
    "    # First Fully Connected Layer\n",
    "    with tf.variable_scope(\"full1\") as scope:\n",
    "        # Fully connected layer will have 384 outputs.\n",
    "        full_weight1 = truncated_normal_var(name=\"full_mult1\",shape=[reshaped_dim,384],dtype=tf.float32)\n",
    "        full_bias1 = zero_var(name=\"full_bias1\",shape=[384],dtype=tf.float32)\n",
    "        full_layer1 = tf.nn.relu(tf.add(tf.matmul(reshaped_output,full_weight1),full_bias1))\n",
    "        \n",
    "    # Second Fully Connected Layer\n",
    "    with tf.variable_scope(\"full2\") as scope:\n",
    "        # Second fully connected layer has 192 outputs.\n",
    "        full_weight2 = truncated_normal_var(name=\"full_mult2\",shape=[384,192],dtype=tf.float32)\n",
    "        full_bias2 = zero_var(name=\"full_bias2\",shape=[192],dtype=tf.float32)\n",
    "        full_layer2 = tf.nn.relu(tf.add(tf.matmul(full_layer1,full_weight2),full_bias2))\n",
    "        \n",
    "    # Final Fully Connected Layer -> 10 categories for output (num_targets)\n",
    "    with tf.variable_scope(\"full3\") as scope:\n",
    "        # Final fully connected layer has 10 (num_targets) outputs.\n",
    "        full_weight3 = truncated_normal_var(name=\"full_mult3\",shape=[192,num_targets],dtype=tf.float32)\n",
    "        full_bias3 = zero_var(name=\"full_bias3\",shape=[num_targets],dtype=tf.float32)\n",
    "        final_output = tf.add(tf.matmul(full_layer2,full_weight3),full_bias3)\n",
    "        \n",
    "    return (final_output)\n",
    "\n",
    "# Loss function\n",
    "def cifar_loss(logits,targets):\n",
    "    # Get rid of extra dimensions and cast targets into integers\n",
    "    targets = tf.squeeze(tf.cast(targets,tf.int32))\n",
    "    # Calculate cross entropy from logits and targets\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=targets)\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy,name=\"cross_entropy\")\n",
    "    return (cross_entropy_mean)\n",
    "# help(tf.train.exponential_decay)\n",
    "# Train step\n",
    "def train_step(loss_values,generation_num):\n",
    "    # Our learning rate is an exponential decay after we wait a fair number of generations\n",
    "    model_learning_rate = tf.train.exponential_decay(learning_rate=learning_rate,\n",
    "                                                     global_step=generation_num,\n",
    "                                                     decay_steps=num_gens_to_wait,\n",
    "                                                    decay_rate=lr_decay,staircase=True)\n",
    "    # Create optimizer\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(model_learning_rate)\n",
    "    train_step = my_optimizer.minimize(loss_values)\n",
    "    return (train_step)\n",
    "\n",
    "# Create optimizer\n",
    "def accuracy_of_batch(logits,targets):\n",
    "    # Make sure targets are integers and drop extra dimensions\n",
    "    targets = tf.squeeze(tf.cast(targets,tf.int32))\n",
    "    # Get predicted values by finding which logit is the greatest\n",
    "    batch_predictions = tf.cast(tf.argmax(logits,1),tf.int32)\n",
    "    # Check if they are equal across the batch\n",
    "    predicted_correctly = tf.equal(batch_predictions,targets)\n",
    "    # Average the 1's and 0's (True's and False's) across the batch size\n",
    "    accuracy = tf.reduce_mean(tf.cast(predicted_correctly,tf.float32))\n",
    "    \n",
    "    return (accuracy)\n",
    "\n",
    "# Get data\n",
    "print('Getting/Transforming Data.')\n",
    "# Initialize the data pipeline\n",
    "images,targets = input_pipline(batch_size=batch_size,train_logical=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
