{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stylenet / Neural-Style\n",
    "=======================\n",
    "\n",
    "The purpose of this script is to illustrate how to do stylenet in Tensorflow.  We reference the following [paper](https://arxiv.org/abs/1508.06576) for this algorithm.\n",
    "\n",
    "## Prerequisites\n",
    " * Download the VGG-verydeep-19.mat file [here](http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat).\n",
    " * You must download two images, a [style image](https://github.com/nfmcclure/tensorflow_cookbook/blob/master/08_Convolutional_Neural_Networks/images/starry_night.jpg?raw=true) and a [content image](https://github.com/nfmcclure/tensorflow_cookbook/blob/master/08_Convolutional_Neural_Networks/images/book_cover.jpg?raw=true) for the algorithm to blend. (Image links are to the images used in the book.)\n",
    "\n",
    "The algorithm will output temporary images during training.\n",
    "\n",
    "![Stylenet Example](https://github.com/nfmcclure/tensorflow_cookbook/blob/master/08_Convolutional_Neural_Networks/images/05_stylenet_ex.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tensorflow for Stylenet/NeuralStyle\n",
    "# ---------------------------------------\n",
    "#\n",
    "# We use two images, an original image and a style image\n",
    "# and try to make the original image in the style of the style image.\n",
    "#\n",
    "# Reference paper:\n",
    "# https://arxiv.org/abs/1508.06576\n",
    "#\n",
    "# Need to download the model 'imagenet-vgg-verydee-19.mat' from:\n",
    "#   http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
    "\n",
    "import os\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# Start a graph session\n",
    "sess = tf.Session()\n",
    "current_dir = os.path.dirname(os.path.abspath(__name__))\n",
    "os.chdir(current_dir)\n",
    "data_dir = \"stylenet\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "# Image Files\n",
    "original_image_file = os.path.join(data_dir,\"book_cover.jpg\")\n",
    "style_image_file = os.path.join(data_dir,\"starry_night.jpg\")\n",
    "vgg_verydeep_file = os.path.join(data_dir,\"imagenet-vgg-verydeep-19.mat\")\n",
    " # Download file\n",
    "def progress(block_num,block_size,total_size):\n",
    "    progress_info = [float(block_num * block_size) / float(total_size) * 100.0]\n",
    "    print('\\r Downloading- {:.2f}%'.format(*progress_info), end=\"\")\n",
    "if not os.path.isfile(vgg_verydeep_file):\n",
    "    vgg_url = \"http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\"\n",
    "    print(\"downloading vgg_verydeep file........\")\n",
    "    urllib.request.urlretrieve(vgg_url,vgg_verydeep_file,progress)\n",
    "\n",
    "if not os.path.isfile(original_image_file)    :\n",
    "    original_image_url = \"https://github.com/nfmcclure/tensorflow_cookbook/blob/master/08_Convolutional_Neural_Networks/images/book_cover.jpg?raw=true\"\n",
    "    print(\"downloading original image file.......\")\n",
    "    urllib.request.urlretrieve(original_image_url,original_image_file,progress)\n",
    "    \n",
    "if not os.path.isfile(style_image_file):\n",
    "    style_image_url = \"https://github.com/nfmcclure/tensorflow_cookbook/blob/master/08_Convolutional_Neural_Networks/images/starry_night.jpg?raw=true\"\n",
    "    print(\"\\rdownloading style image file.......\")\n",
    "    urllib.request.urlretrieve(style_image_url,style_image_file,progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Arguments\n",
    "original_image_weight=5.0\n",
    "style_image_weight=200.0\n",
    "regularization_weight=50.0\n",
    "learning_rate=0.1\n",
    "generations=10000\n",
    "output_generations=500\n",
    "# Read in images\n",
    "original_image=scipy.misc.imread(original_image_file)\n",
    "style_image=scipy.misc.imread(style_image_file)\n",
    "# Get shape of target and make the style image the same\n",
    "target_shape=original_image.shape #(326, 458, 3)\n",
    "# help(scipy.misc.imresize)\n",
    "# print(target_shape[1])#458\n",
    "# print(style_image.shape)#(507, 640, 3)\n",
    "style_image = scipy.misc.imresize(style_image,target_shape[1] / style_image.shape[1])\n",
    "# print(style_image.shape)#(362, 458, 3)\n",
    "\n",
    "# VGG-19 Layer Setup\n",
    "# From paper\n",
    "vgg_layers = ['conv1_1', 'relu1_1',\n",
    "              'conv1_2', 'relu1_2', 'pool1',\n",
    "              'conv2_1', 'relu2_1',\n",
    "              'conv2_2', 'relu2_2', 'pool2',\n",
    "              'conv3_1', 'relu3_1',\n",
    "              'conv3_2', 'relu3_2',\n",
    "              'conv3_3', 'relu3_3',\n",
    "              'conv3_4', 'relu3_4', 'pool3',\n",
    "              'conv4_1', 'relu4_1',\n",
    "              'conv4_2', 'relu4_2',\n",
    "              'conv4_3', 'relu4_3',\n",
    "              'conv4_4', 'relu4_4', 'pool4',\n",
    "              'conv5_1', 'relu5_1',\n",
    "              'conv5_2', 'relu5_2',\n",
    "              'conv5_3', 'relu5_3',\n",
    "              'conv5_4', 'relu5_4']\n",
    "# Extract weights and matrix means\n",
    "def extract_net_info(path_to_params):\n",
    "    vgg_data = scipy.io.loadmat(path_to_params)\n",
    "    normalization_matrix = vgg_data['normalization'][0][0][0]\n",
    "    mat_mean = np.mean(normalization_matrix,axis=(0,1))\n",
    "    network_weights = vgg_data['layers'][0]\n",
    "    return (mat_mean,network_weights)\n",
    "\n",
    "# Create the VGG-19 Network\n",
    "def vgg_network(network_weights,init_image):\n",
    "    network = {}\n",
    "    image = init_image\n",
    "    for i,layer in enumerate(vgg_layers):\n",
    "        if layer[0] == 'c':\n",
    "            weights,bias = network_weights[i][0][0][0][0]\n",
    "            weights = np.transpose(weights,[1,0,2,3])\n",
    "            bias = bias.reshape(-1)\n",
    "            conv_layer = tf.nn.conv2d(image,filter=tf.constant(weights),strides=[1,1,1,1],padding=\"SAME\")\n",
    "            image = tf.nn.bias_add(conv_layer,bias)\n",
    "        elif layer[0] == 'r':\n",
    "            image = tf.nn.relu(image)\n",
    "        else:\n",
    "            image = tf.nn.max_pool(image,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "        \n",
    "        network[layer] = image\n",
    "   \n",
    "    return (network)\n",
    "# Here we define which layers apply to the original or style image\n",
    "original_layer = 'relu4_2'\n",
    "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']\n",
    "# Get network parameters\n",
    "normalization_mean,network_weights = extract_net_info(vgg_verydeep_file)\n",
    "shape = (1,) + original_image.shape\n",
    "style_shape = (1,) + style_image.shape\n",
    "\n",
    "original_features = {}\n",
    "style_features = {}\n",
    "# Get network parameters\n",
    "image = tf.placeholder('float',shape=shape)\n",
    "vgg_net = vgg_network(network_weights,image)\n",
    "# Normalize original image\n",
    "original_minus_mean = original_image - normalization_mean\n",
    "original_norm = np.array([original_minus_mean])\n",
    "original_features[original_layer] = sess.run(vgg_net[original_layer],feed_dict={image: original_norm})\n",
    "\n",
    "# Get style image network\n",
    "image = tf.placeholder('float',shape=style_shape)\n",
    "vgg_net = vgg_network(network_weights,image)\n",
    "style_minus_mean = style_image - normalization_mean\n",
    "style_norm = np.array([style_minus_mean])\n",
    "for layer in style_layers:\n",
    "    layer_output = sess.run(vgg_net[layer],feed_dict={image:style_norm})\n",
    "    layer_output = np.reshape(layer_output,(-1,layer_output.shape[3]))\n",
    "    style_gram_matrix = np.matmul(layer_output.T,layer_output) / layer_output.size\n",
    "    style_features[layer] = style_gram_matrix\n",
    "\n",
    "# Make Combined Image\n",
    "initial = tf.random_normal(shape) * 0.05\n",
    "image = tf.Variable(initial)\n",
    "vgg_net = vgg_network(network_weights,image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 325, 458, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loss\n",
    "original_loss = original_image_weight * (2 * tf.nn.l2_loss(vgg_net[original_layer] - original_features[original_layer]) / original_features[original_layer].size)\n",
    "# Loss from Style Image\n",
    "style_loss_sum = 0\n",
    "style_loss_vec = []\n",
    "for style_layer in style_layers:\n",
    "    layer = vgg_net[style_layer]\n",
    "    feats,height,width,channels = [x.value for x in layer.get_shape()]\n",
    "    size = height * width * channels\n",
    "    features = tf.reshape(layer,(-1,channels))\n",
    "    style_gram_matrix = tf.matmul(tf.transpose(features),features) / size\n",
    "    style_expected = style_features[style_layer]\n",
    "    style_loss = 2 * tf.nn.l2_loss(style_gram_matrix - style_expected) / style_expected.size\n",
    "    style_loss_vec.append(style_loss)\n",
    "\n",
    "style_loss_sum += style_image_weight * tf.reduce_sum(style_loss_vec)\n",
    "# To Smooth the resuts, we add in total variation loss  \n",
    "print(image[:,1:,:,:].get_shape())#(1, 325, 458, 3)\n",
    "total_var_x = sess.run(tf.reduce_prod(image[:,1:,:,:].get_shape())) #output = 1*325*458*3=446550\n",
    "# print(total_var_x)\n",
    "total_var_y = sess.run(tf.reduce_prod(image[:,:,1:,:].get_shape()))\n",
    "first_term = regularization_weight * 2\n",
    "second_term_numerator = tf.nn.l2_loss(image[:,1:,:,:] - image[:,:shape[1]-1,:,:])\n",
    "second_term = second_term_numerator / total_var_y\n",
    "third_term = tf.nn.l2_loss(image[:,:,1:,:] - image[:,:,:shape[2]-1,:]) / total_var_x\n",
    "total_variation_loss = first_term * (second_term + third_term)\n",
    "# Combined Loss\n",
    "loss = original_loss + style_loss_sum + total_variation_loss\n",
    "# Declare Optimization Algorithm\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "# Initialize Variables and start Training\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin training....\n"
     ]
    }
   ],
   "source": [
    "print(\"begin training....\")\n",
    "for i in range(generations):\n",
    "    sess.run(train_step)\n",
    "    # Print update and save temporary output\n",
    "    if (i + 1) / output_generations == 0:\n",
    "        print(\"Generation {} out of {}\".format((i + 1),generations))\n",
    "        image_eval = sess.run(image)\n",
    "        best_image_add_mean = image_eval.reshape(shape[1:]) + normalization_mean\n",
    "        output_file = os.path.join(data_dir,\"temp_output_{}.jpg\".format(i))\n",
    "        scipy.misc.imsave(output_file,best_image_add_mean)\n",
    "        \n",
    "# Save final image\n",
    "print(\"save final image\")\n",
    "image_eval = sess.run(image)\n",
    "final_image_add_mean = image_eval.reshape(shape[1:]) + normalization_mean\n",
    "output_file = os.path.join(data_dir,\"final_output.jpg\")\n",
    "scipy.misc.imsave(output_file,final_image_add_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
